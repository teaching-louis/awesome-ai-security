# Awesome AI Security [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
Curation of awesome AI security resources. If you want to contribute, create a PR or contact me [LinkedIn](https://linkedin.com/in/louiscremen)

Head over to the [wiki](https://github.com/teaching-louis/awesome-ai-security/wiki/Home) tab for a table of contents

# AI Security Authorities


## EU Artificial Intelligence Act
* [Homepage](https://artificialintelligenceact.eu/) - A lot of their main resources are shown on the homepage if you need a quick place to understand EU AI compliance
    * [High Level Summary](https://artificialintelligenceact.eu/high-level-summary/)
    * [AI Act Explorer](https://artificialintelligenceact.eu/ai-act-explorer/)


## ISACA Resources
* [Artificial Intelligence Audit Toolkit](https://store.isaca.org/s/store#/store/browse/detail/a2S4w000007kB9pEAE) - AI Audit Toolkit (PAID)


## Mitre Resources
* [ATLAS Matrix](https://atlas.mitre.org/matrices/ATLAS) - Great collection of TTPs for AI/ML attacks
* [MITRE AI Maturity Model](https://aimaturitymodel.mitre.org/) - Decent document demonstrating an approach to maturity an organisation utilising AI 
* [SAFE-AI](https://www.compliancehub.wiki/content/files/2025/07/mitresafeAI.pdf) - I'm not sure why I can't find this on the MITRE website, but it is an excellent framework mapping ATLAS and NIST. As with many documents, a lot of the good stuff is in the appendix, definitely worth checking out


## NIST Resources
* [NIST AI Risk Management Framework (AI RMF 1.0)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf) - Great document. Definitely worth looking at
    * [Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf)
    * [NIST AI RMF Playbook](https://airc.nist.gov/airmf-resources/playbook/)
* [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://www.nist.gov/publications/adversarial-machine-learning-taxonomy-and-terminology-attacks-and-mitigations-0)
* [SP 800-53 Control Overlays for Securing AI Systems Concept Paper](https://csrc.nist.gov/csrc/media/Projects/cosais/documents/NIST-Overlays-SecuringAI-concept-paper.pdf)


## OWASP Resources
* [GenAI](https://genai.owasp.org/) - Collection of all of OWASP's LLM and GenAI Projects
    * [LLM Top 10 Risk & Mitigations for LLMs and Gen AI Apps](https://genai.owasp.org/llm-top-10/)
    * [AI Security Solutions Landscape](https://genai.owasp.org/ai-security-solutions-landscape/)
    * [LLM Applications Cybersecurity and Governance Checklist â€“ English](https://genai.owasp.org/resource/llm-applications-cybersecurity-and-governance-checklist-english/)
    * [AI Maturity Assessment](https://owasp.org/www-project-ai-maturity-assessment/)


# People to follow
* Daniel Miessler - Followed his work closely when he was in security (and he once followed mine) - now I find I align really well with his takes on AI Security too
    * [LinkedIn](https://www.linkedin.com/in/danielmiessler/)
    * [Github](https://github.com/danielmiessler) - If you've used SecLists, you've seen some of Daniel's stuff. Maybe you've used Fabric too?
* Sandy Dunn - Core Team OWASP Top Ten for LLM
    * [LinkedIn](https://www.linkedin.com/in/sandydunnciso/)
    * [Github](https://github.com/subzer0girl2)
* Disesdi Susanna - AI Security Researcher - Has some great MLSecOps resources [here](https://github.com/disesdi/mlsecops_references)
    * [LinkedIn](https://www.linkedin.com/in/disesdi/)
    * [Github](https://github.com/disesdi)
